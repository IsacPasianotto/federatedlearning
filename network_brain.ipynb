{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T10:09:38.526179Z",
     "start_time": "2024-07-01T10:09:38.522550Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "import os\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bb062f0-17d1-414e-920d-868fa3c194fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Class overloading the torch.utils.data.Dataset class to \n",
    "    create a custom dataset object\n",
    "    \"\"\"\n",
    "    def __init__ (self, images, labels):\n",
    "        self.images = images.float()\n",
    "        self.labels = labels.long()\n",
    "\n",
    "\n",
    "    def __len__ (self): \n",
    "        return(len(self.images))\n",
    "\n",
    "    def __getitem__ (self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "    \n",
    "    def __str__(self):\n",
    "        output  = \"Images shape: \" + str(self.images.shape) + \"\\n\"\n",
    "        output += \"Labels shape: \" + str(self.labels.shape) + \"\\n\"\n",
    "        countClasses = torch.bincount(self.labels)\n",
    "        for i in range(len(countClasses)):\n",
    "            output += self.labelStr(i) + \":  \" + str(countClasses[i].item()) + \"\\n\"\n",
    "        return output\n",
    "    \n",
    "    def labelStr(self,label):\n",
    "            return \"Meningioma\" if label == 0 else \"Glioma\" if label == 1 else \"Pituitary tumor\" if label == 2 else \"unknown\"\n",
    "    \n",
    "    def shuffle(self):\n",
    "        idx = torch.randperm(self.__len__())\n",
    "        self.images = self.images[idx]\n",
    "        self.labels = self.labels[idx]\n",
    "        \n",
    "    def train_val_test_split(self, train_percentage=0.7, val_percentage=0.15, test_percentage=0.15):\n",
    "        # split the data\n",
    "        self.shuffle()\n",
    "        train_data = self[:int(train_percentage*self.__len__())]\n",
    "        val_data = self[int(train_percentage*self.__len__()):int((train_percentage+val_percentage)*self.__len__())]\n",
    "        test_data = self[int((train_percentage+val_percentage)*self.__len__()):]\n",
    "        return Dataset(train_data[0], train_data[1]), Dataset(val_data[0], val_data[1]), Dataset(test_data[0], test_data[1])\n",
    "    \n",
    "    def separateClasses(self):\n",
    "        nClasses = torch.max(self.labels)+1\n",
    "        return [torch.utils.data.Subset(self, torch.where(self.labels == i)[0]) for i in range(nClasses)]\n",
    "    \n",
    "    def splitClasses(self, percentPerClass, save=False):\n",
    "        \"\"\"Split the dataset into multiple datasets, one for each class, and saves them if desired\n",
    "\n",
    "        Args:\n",
    "            percentPerClass (List[List[float]]): List of lists of floats representing the percentage of each class to be in each subset\n",
    "            save (bool, optional): Decide if to save the created datasets or not. Defaults to False.\n",
    "\n",
    "        Raises:\n",
    "            ValueError: raised if the number of percentages arrays is different from the number of classes\n",
    "            ValueError: raised if the sum of the percentages is not 1 for each class\n",
    "\n",
    "        Returns:\n",
    "            List[torch.utils.data.Subset]: List of the created datasets\n",
    "        \"\"\"\n",
    "        datasets = self.separateClasses()\n",
    "        nClasses = len(datasets)\n",
    "        if len(percentPerClass) != nClasses:\n",
    "            raise ValueError(f\"The number of percentages arrays should be equal to the number of classes ({nClasses})\")\n",
    "        for percentList in percentPerClass:\n",
    "            if not torch.isclose(torch.sum(percentList), torch.tensor(1.0), atol=1e-6):\n",
    "                raise ValueError(f\"The sum of the percentages of each class should be 1, but got {sum(percentList)} in {percentList}\")\n",
    "        output = []\n",
    "        for i in range(nClasses):\n",
    "            data = torch.utils.data.random_split(datasets[i], percentPerClass[i])\n",
    "            if save:\n",
    "                label = self.labelStr(i)\n",
    "                os.makedirs(f\"dataBrain/{label}\", exist_ok=True)\n",
    "                for j, subset in enumerate(data):\n",
    "                    # Extract data from the subset\n",
    "                    images = [subset.dataset[idx][0] for idx in subset.indices]\n",
    "                    labels = [subset.dataset[idx][1] for idx in subset.indices]\n",
    "                    # Create a new dataset\n",
    "                    newData = Dataset(torch.stack(images), torch.tensor(labels))\n",
    "                    # Save the new dataset\n",
    "                    torch.save(newData, f\"dataBrain/{label}/{label}{int(percentPerClass[i][j]*100)}_{j}.pt\")\n",
    "            output.append(data)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cd564454eb7ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T10:03:46.720407Z",
     "start_time": "2024-07-01T10:03:46.597549Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = torch.load('data/BrainCancerDataset.pt')\n",
    "# Images shape: torch.Size([3049, 1, 512, 512])\n",
    "# Labels shape: torch.Size([3049])\n",
    "# Meningioma:       708 images\n",
    "# Glioma:          1426 images\n",
    "# Pituitary tumor:  915 images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9998323",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usage example for splitClasses function\n",
    "perc = [torch.tensor([0.6, 0.3, 0.1]),  # Meningioma\n",
    "        torch.tensor([0.5, 0.5]),       # Glioma\n",
    "        torch.tensor([0.7, 0.3]) ]      # Pituitary tumor\n",
    "# (we expect the split to be performed with the same number of subsets for each class actually,\n",
    "# but the function also allows to have different numbers)\n",
    "datasets = data.splitClasses(perc, save=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6012ec34a1726fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T10:03:46.726076Z",
     "start_time": "2024-07-01T10:03:46.722696Z"
    }
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4964f602b0b5cf63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T10:03:46.755446Z",
     "start_time": "2024-07-01T10:03:46.746476Z"
    }
   },
   "outputs": [],
   "source": [
    "class BrainClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BrainClassifier, self).__init__()\n",
    "\n",
    "        # Define layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)  # Grayscale images\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Calculate the input size of the fully connected layer according to the output of the conv layers\n",
    "        self.fc_input_size = 64 * 64 * 64  # Ensure this calculation matches the output size of the conv layers\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 3)  # 3 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convs \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # fully connected \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80f7e12-4c43-4d31-8b15-cc66150232d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a ResNet block\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class BrainClassifierBis(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BrainClassifierBis, self).__init__()\n",
    "\n",
    "        # Define layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.resnet_block1 = ResNetBlock(in_channels=16, out_channels=32, stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.resnet_block2 = ResNetBlock(in_channels=32, out_channels=64, stride=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Calculate the input size of the fully connected layer according to the output of the conv layers\n",
    "        self.fc_input_size = 64 * 64 * 64  # Ensure this calculation matches the output size of the conv layers\n",
    "\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 512)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        self.fc4 = nn.Linear(512, 3)  # 3 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutions\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.resnet_block1(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.resnet_block2(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # Fully connected layers with dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28c5deb61e83d28b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T10:03:46.770594Z",
     "start_time": "2024-07-01T10:03:46.763063Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the training loop\n",
    "def train(model, train_data, val_data, epochs=10, lr=0.001, wd=1e-4):\n",
    "    # Define the loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Define the optimizer\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=wd)  # L2 regularization with weight_decay\n",
    "\n",
    "    # Store the losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Move model to the appropriate device\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Create a progress bar for the training loop\n",
    "    epoch_bar = tqdm(range(epochs), desc='Epochs')\n",
    "    \n",
    "    for epoch in epoch_bar:\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "\n",
    "        epoch_losses = []\n",
    "        # Iterate over the training data\n",
    "        for i, (img, label) in enumerate(train_data):\n",
    "            # Move data to the appropriate device\n",
    "            img, label = img.to(device), label.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            y_pred = model(img)\n",
    "            # Compute the loss\n",
    "            loss = criterion(y_pred, label.long())\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "            # Store the loss\n",
    "            epoch_losses.append(loss.item())\n",
    "\n",
    "        # compute the mean of the losses \n",
    "        epoch_losses_th = torch.tensor(epoch_losses)\n",
    "        epoch_mean_losses = torch.mean(epoch_losses_th)\n",
    "        train_losses.append(epoch_mean_losses)\n",
    "        \n",
    "        # Set the model to evaluation mode\n",
    "        model.eval()\n",
    "        # Compute the validation loss\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for img, label in val_data:\n",
    "                # Move data to the appropriate device\n",
    "                img, label = img.to(device), label.to(device)\n",
    "                y_pred = model(img)\n",
    "                loss = criterion(y_pred, label.long())\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_losses.append(val_loss / len(val_data))\n",
    "        \n",
    "        # update the progress bar\n",
    "        epoch_bar.set_postfix({'Training Loss': train_losses[-1], 'Validation Loss': val_losses[-1]})\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12840732-1fb9-43cc-8500-bdad7e576101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  set the seed before the split\n",
    "torch.manual_seed(42)\n",
    "data_train, data_val, data_test = data.train_val_test_split()\n",
    "\n",
    "# Create the DataLoaders\n",
    "train_loader = DataLoader(data_train, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(data_val, batch_size=64, shuffle=False)\n",
    "# test_loader = DataLoader(data_test, batch_size=data_test.__len__(), shuffle=False)\n",
    "test_loader = DataLoader(data_test, batch_size=128, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440cc3f9e9008b8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T10:08:49.203801Z",
     "start_time": "2024-07-01T10:03:46.853279Z"
    }
   },
   "outputs": [],
   "source": [
    "# Example instantiation and trainin\n",
    "model = BrainClassifierBis()\n",
    "tstart = time.time()\n",
    "\n",
    "train_losses, val_losses = train(model, train_loader, val_loader, epochs=350, lr=0.0000005)\n",
    "\n",
    "tend = time.time()\n",
    "print(\"Time elapsed: \", tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accdc5d14f252460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T10:11:41.023967Z",
     "start_time": "2024-07-01T10:11:40.801571Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c179c7-7984-4772-9b88-15d7fab72f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights\n",
    "torch.save(model.state_dict(), 'Brain_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d61e67-0023-4958-a540-acc5e26b136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BrainClassifier()\n",
    "# model.to(device)\n",
    "# model.load_state_dict(torch.load('./Brain_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355316fc-58fe-42e0-abe3-804499512ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(test_loader))\n",
    "model.eval()\n",
    "y_pred = model(x.to(device)).argmax(1)\n",
    "# y --> label vere\n",
    "# y_pred --> label modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e249c49b-12ee-476a-b65d-7a67b979278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for img, label in test_loader:\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        y_pred = model(img)\n",
    "        correct += (y_pred.argmax(1) == label).sum().item()\n",
    "        total += label.size(0)\n",
    "\n",
    "print(f'Accuracy: {correct / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f704cdd-9f4f-4e82-b17c-df8406cbfade",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = BrainClassifierBis()\n",
    "model2 = model2.to(device)\n",
    "model2.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for img, label in test_loader:\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        y_pred = model2(img.float().to(device))\n",
    "        correct += (y_pred.argmax(1) == label).sum().item()\n",
    "        total += label.size(0)\n",
    "\n",
    "print(f'Accuracy: {correct / total}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c961de99-85e0-466a-8d0c-b68929dff8f4",
   "metadata": {},
   "source": [
    "## Test with different learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d91179e-4f9c-4919-b19d-8159cb0c7d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example instantiation and trainin\n",
    "model = BrainClassifierBis()\n",
    "tstart = time.time()\n",
    "\n",
    "# increase the learning rate by 10\n",
    "train_losses, val_losses = train(model, train_loader, val_loader, epochs=250, lr=0.000001, wd=1e-5)\n",
    "\n",
    "tend = time.time()\n",
    "print(\"Time elapsed: \", tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b091d34-cccf-40eb-a530-859b6da7ccba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4f8b51-00fb-444a-943c-0b5ae4dfcb1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(test_loader))\n",
    "model.eval()\n",
    "y_pred = model(x.to(device)).argmax(1)\n",
    "# y --> label vere\n",
    "# y_pred --> label modello# compute the accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for img, label in test_loader:\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        y_pred = model(img)\n",
    "        correct += (y_pred.argmax(1) == label).sum().item()\n",
    "        total += label.size(0)\n",
    "\n",
    "print(f'Accuracy: {correct / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a48e14f-435e-4b16-8e46-c48ad693cb41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = BrainClassifierBis()\n",
    "model2 = model2.to(device)\n",
    "model2.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for img, label in test_loader:\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        y_pred = model2(img.float().to(device))\n",
    "        correct += (y_pred.argmax(1) == label).sum().item()\n",
    "        total += label.size(0)\n",
    "\n",
    "print(f'Accuracy: {correct / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aebec429-0d69-48b7-ba99-e21614a92ff0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
