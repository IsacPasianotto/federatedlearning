{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T10:09:38.526179Z",
     "start_time": "2024-07-01T10:09:38.522550Z"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import time\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torch.utils.data import DataLoader\n",
    "from tqdm import trange, tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6bb062f0-17d1-414e-920d-868fa3c194fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    \"\"\"\n",
    "    Class overloading the torch.utils.data.Dataset class to \n",
    "    create a custom dataset object\n",
    "    \"\"\"\n",
    "    def __init__ (self, images, labels):\n",
    "        self.images = images.float()\n",
    "        self.labels = labels.long()\n",
    "\n",
    "\n",
    "    def __len__ (self): \n",
    "        return(len(self.images))\n",
    "\n",
    "    def __getitem__ (self, idx):\n",
    "        return self.images[idx], self.labels[idx]\n",
    "    \n",
    "    def shuffle(self):\n",
    "        idx = torch.randperm(self.__len__())\n",
    "        self.images = self.images[idx]\n",
    "        self.labels = self.labels[idx]\n",
    "    \n",
    "    def train_val_test_split(self, train_percentage=0.7, val_percentage=0.15, test_percentage=0.15):\n",
    "        # split the data\n",
    "        self.shuffle()\n",
    "        train_data = self[:int(train_percentage*self.__len__())]\n",
    "        val_data = self[int(train_percentage*self.__len__()):int((train_percentage+val_percentage)*self.__len__())]\n",
    "        test_data = self[int((train_percentage+val_percentage)*self.__len__()):]\n",
    "        return Dataset(train_data[0], train_data[1]), Dataset(val_data[0], val_data[1]), Dataset(test_data[0], test_data[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7cd564454eb7ebf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T10:03:46.720407Z",
     "start_time": "2024-07-01T10:03:46.597549Z"
    }
   },
   "outputs": [],
   "source": [
    "# load the data\n",
    "data = torch.load('data/BrainCancerDataset.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a6012ec34a1726fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T10:03:46.726076Z",
     "start_time": "2024-07-01T10:03:46.722696Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4964f602b0b5cf63",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T10:03:46.755446Z",
     "start_time": "2024-07-01T10:03:46.746476Z"
    }
   },
   "outputs": [],
   "source": [
    "class BrainClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BrainClassifier, self).__init__()\n",
    "\n",
    "        # Define layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)  # Grayscale images\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=16, out_channels=32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Calculate the input size of the fully connected layer according to the output of the conv layers\n",
    "        self.fc_input_size = 64 * 64 * 64  # Ensure this calculation matches the output size of the conv layers\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.fc4 = nn.Linear(512, 3)  # 3 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # convs \n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool2(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # fully connected \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f80f7e12-4c43-4d31-8b15-cc66150232d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a ResNet block\n",
    "class ResNetBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResNetBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "\n",
    "class BrainClassifierBis(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BrainClassifierBis, self).__init__()\n",
    "\n",
    "        # Define layers\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=16, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.resnet_block1 = ResNetBlock(in_channels=16, out_channels=32, stride=1)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.resnet_block2 = ResNetBlock(in_channels=32, out_channels=64, stride=1)\n",
    "        self.pool3 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "        # Calculate the input size of the fully connected layer according to the output of the conv layers\n",
    "        self.fc_input_size = 64 * 64 * 64  # Ensure this calculation matches the output size of the conv layers\n",
    "\n",
    "        self.fc1 = nn.Linear(self.fc_input_size, 512)\n",
    "        self.dropout1 = nn.Dropout(0.1)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "        self.fc3 = nn.Linear(512, 512)\n",
    "        self.dropout3 = nn.Dropout(0.1)\n",
    "        self.fc4 = nn.Linear(512, 3)  # 3 classes\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Convolutions\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool1(x)\n",
    "\n",
    "        x = self.resnet_block1(x)\n",
    "        x = self.pool2(x)\n",
    "\n",
    "        x = self.resnet_block2(x)\n",
    "        x = self.pool3(x)\n",
    "\n",
    "        x = self.flatten(x)\n",
    "\n",
    "        # Fully connected layers with dropout\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout1(x)\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.dropout3(x)\n",
    "        x = self.fc4(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28c5deb61e83d28b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T10:03:46.770594Z",
     "start_time": "2024-07-01T10:03:46.763063Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the training loop\n",
    "def train(model, train_data, val_data, epochs=10, lr=0.001):\n",
    "    # Define the loss function\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    # Define the optimizer\n",
    "    # optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr,  weight_decay=1e-4)  # L2 regularization with weight_decay\n",
    "\n",
    "    # Store the losses\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    # Move model to the appropriate device\n",
    "    # device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model.to(device)\n",
    "\n",
    "    # Create a progress bar for the training loop\n",
    "    epoch_bar = tqdm(range(epochs), desc='Epochs')\n",
    "    \n",
    "    for epoch in epoch_bar:\n",
    "        # Set the model to training mode\n",
    "        model.train()\n",
    "\n",
    "        epoch_losses = []\n",
    "        # Iterate over the training data\n",
    "        for i, (img, label) in enumerate(train_data):\n",
    "            # Move data to the appropriate device\n",
    "            img, label = img.to(device), label.to(device)\n",
    "\n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            # Forward pass\n",
    "            y_pred = model(img)\n",
    "            # Compute the loss\n",
    "            loss = criterion(y_pred, label.long())\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            # Update the weights\n",
    "            optimizer.step()\n",
    "            # Store the loss\n",
    "            epoch_losses.append(loss.item())\n",
    "\n",
    "        # compute the mean of the losses \n",
    "        epoch_losses_th = torch.tensor(epoch_losses)\n",
    "        epoch_mean_losses = torch.mean(epoch_losses_th)\n",
    "        train_losses.append(epoch_mean_losses)\n",
    "        \n",
    "        # Set the model to evaluation mode\n",
    "        model.eval()\n",
    "        # Compute the validation loss\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for img, label in val_data:\n",
    "                # Move data to the appropriate device\n",
    "                img, label = img.to(device), label.to(device)\n",
    "                y_pred = model(img)\n",
    "                loss = criterion(y_pred, label.long())\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_losses.append(val_loss / len(val_data))\n",
    "        \n",
    "        # update the progress bar\n",
    "        epoch_bar.set_postfix({'Training Loss': train_losses[-1], 'Validation Loss': val_losses[-1]})\n",
    "\n",
    "    return train_losses, val_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12840732-1fb9-43cc-8500-bdad7e576101",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  set the seed before the split\n",
    "torch.manual_seed(42)\n",
    "data_train, data_val, data_test = data.train_val_test_split()\n",
    "\n",
    "# Create the DataLoaders\n",
    "train_loader = DataLoader(data_train, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(data_val, batch_size=32, shuffle=False)\n",
    "# test_loader = DataLoader(data_test, batch_size=data_test.__len__(), shuffle=False)\n",
    "test_loader = DataLoader(data_test, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440cc3f9e9008b8a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T10:08:49.203801Z",
     "start_time": "2024-07-01T10:03:46.853279Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epochs:   0%|                                                                     | 0/100 [00:00<?, ?it/s]/orfeo/cephfs/home/dssc/ipasia00/deepenv/lib64/python3.9/site-packages/torch/nn/modules/conv.py:456: UserWarning: Attempt to open cnn_infer failed: handle=0 error: libcudnn_cnn_infer.so.8: cannot open shared object file: No such file or directory (Triggered internally at ../aten/src/ATen/native/cudnn/Conv_v8.cpp:81.)\n",
      "  return F.conv2d(input, weight, bias, self.stride,\n",
      "Epochs:  90%|██████▎| 90/100 [12:57<01:26,  8.67s/it, Training Loss=tensor(0.0021), Validation Loss=0.151]"
     ]
    }
   ],
   "source": [
    "# Example instantiation and trainin\n",
    "model = BrainClassifierBis()\n",
    "tstart = time.time()\n",
    "\n",
    "train_losses, val_losses = train(model, train_loader, val_loader, epochs=100, lr=0.000001)\n",
    "\n",
    "tend = time.time()\n",
    "print(\"Time elapsed: \", tend-tstart)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "accdc5d14f252460",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-07-01T10:11:41.023967Z",
     "start_time": "2024-07-01T10:11:40.801571Z"
    }
   },
   "outputs": [],
   "source": [
    "# plot the losses\n",
    "plt.plot(val_losses, label='Validation Loss')\n",
    "plt.plot(train_losses, label='Training Loss')\n",
    "\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c179c7-7984-4772-9b88-15d7fab72f5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model weights\n",
    "torch.save(model.state_dict(), 'Brain_weights.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d61e67-0023-4958-a540-acc5e26b136a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = BrainClassifier()\n",
    "# model.to(device)\n",
    "# model.load_state_dict(torch.load('./Brain_weights.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355316fc-58fe-42e0-abe3-804499512ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = next(iter(test_loader))\n",
    "model.eval()\n",
    "y_pred = model(x.to(device)).argmax(1)\n",
    "# y --> label vere\n",
    "# y_pred --> label modello"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e249c49b-12ee-476a-b65d-7a67b979278a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the accuracy\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for img, label in test_loader:\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        y_pred = model(img)\n",
    "        correct += (y_pred.argmax(1) == label).sum().item()\n",
    "        total += label.size(0)\n",
    "\n",
    "print(f'Accuracy: {correct / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f704cdd-9f4f-4e82-b17c-df8406cbfade",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = BrainClassifierBis()\n",
    "model2 = model2.to(device)\n",
    "model2.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for img, label in test_loader:\n",
    "        img, label = img.to(device), label.to(device)\n",
    "        y_pred = model2(img.float().to(device))\n",
    "        correct += (y_pred.argmax(1) == label).sum().item()\n",
    "        total += label.size(0)\n",
    "\n",
    "print(f'Accuracy: {correct / total}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d91179e-4f9c-4919-b19d-8159cb0c7d4d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
